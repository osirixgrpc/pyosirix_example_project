{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pyOsiriX Example Project","text":"<p>An example project to demonstrate a method for creating a full project for use in pyOsiriX.</p> <p></p> <p>Tools used here:</p> <ul> <li>PIP: Used for packaging your code for your users.</li> <li>GitHub: Used for CI/CD and version control.</li> <li>DVC: Used for model or data versioning.</li> <li>pyTest: Used for testing your code automatically.</li> <li>MkDocs: Used for generating documentation.</li> <li>bump2version: Used for semantic version control.</li> <li>gRPC: Used to communicate with the server and with osirix.</li> </ul>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at osirixgrpc@gmail.com. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Thanks for your interest in this project - we welcome your help and support!</p>"},{"location":"CONTRIBUTING/#ways-to-contribute","title":"Ways to Contribute","text":"Documentation We encourage feedback on our documentation to improve the user experience and ensure it makes sense. Please see          our instructions for project documentation for more information. Testing We greatly appreciate our testers, who provide core feedback and have a key role in deciding the future of the          project. Please contact us if you would like to become an official tester! Bug Tracking We will endeavour to fix all bugs encountered as soon as possible. If you encounter a bug, please see our          bug reporting section. Feature Suggestions We cannot improve things without good ideas coming from users. If you would like to request a new feature this          can be done as a feature request on the project              issue tracker.  Please note that          acceptance and importance of features will be discussed and agreed by our developers following discussion with          you. We cannot guarantee that all feature requests will be implemented, or how quickly they will be          delivered. Feature Development If you would like to help develop this project, we are keen to improve and evolve every aspect of it. This        includes:        <ul> <li>Optimize CI/CD (all performed in GitHub)</li> <li>Improve the user experience</li> <li>Ensure that key updates to libraries are monitored and fixed within the project.</li> </ul>       Please see the remainder of this documentation to see how this can be done, and let us        know about your ideas!"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>Please see our Code of Conduct for more information.</p>"},{"location":"CONTRIBUTING/#prerequisites","title":"Prerequisites","text":"<p>In order to help contribute to this project there are a few things you will need. Some may not be required  depending on the level contributions you want to make.</p> Mac OsiriX works on macOS.  We currently support (and have tested) compatability of OsiriXgrpc on macOS Monterey and         above, on both Intel and M1/M2/M3 native processors. We always advise ensuring that your operating system is          up-to-date. OsiriX or Horos A copy of the latest OsiriX          app downloaded on your system. This will be crucial for testing the OsiriXgrpc plugin, developing new          features, and authoring new OsiriXgrpc scripts. A free alternative is          Horos. GitHub Account You will need a GitHub account to interact with the source code, create pull requests for new         features that you have developed, and raise new issues or report bugs on the project           issue tracker."},{"location":"CONTRIBUTING/#coding-guidelines","title":"Coding Guidelines","text":""},{"location":"CONTRIBUTING/#project-structure","title":"Project Structure","text":"<p>There are several core files and directories at the root of the project</p> Name Description .github Issue templates and CI/CD workflows for GitHub Actions. data The location for external data. This will not be tracked by Git and data will be downloaded during set-up. docs All externally-facing documentation (definition files in markdown). pyosirix_operations Source code for integrating the project code into OsiriX/Horos through pyOsiriX. tests Automatic unit tests for the project. utilities General utilities for use within the project. .bumpversion.cfg Rules to increment version numbers scattered throughout the project. .gitignore What Git will not keep track of during version control. LICENSE The license for all code within this project. mkdocs.yaml The configuration file for creating documentation with MkDocs. pyproject.toml The configuration file for packaging and uploading this project to the Python Package Index. README.md A symlink to the projects main README.md file located within the docs directory. requirements.txt The core library requirements for the project. VERSION A simple file containing the current version of the project as a string."},{"location":"CONTRIBUTING/#modifying-source-code","title":"Modifying Source Code","text":"<p>When making changes to the source code, we recommend the following process to ensure your contributions can be  efficiently reviewed and integrated:</p> <ol> <li>Fork the Repository Start by forking the repository. This creates your own copy of the project where you can make     your changes. </li> <li>Make Your Changes Implement your changes in your forked repository. To facilitate a smooth review process, we     suggest:<ul> <li>Isolate Changes: Keep your changes focused. Large or complex modifications may require more extensive review and    have a higher chance of being rejected.</li> <li>Communicate Intentions: Let us know about your planned changes in advance. This helps us coordinate contributions    and include them in our release planning.</li> </ul> </li> <li>Submit a Pull Request (PR) Once you're satisfied with your changes, submit them back to the main project via a     pull request. Ensure your PR targets an appropriate branch. For guidance on creating a pull request, see GitHub's     documentation on Creating a pull request from     a fork. </li> <li>Review Process Your pull request will undergo a review by the project maintainers. During this phase:<ul> <li>Merge Upstream Changes: You may be asked to merge changes from the upstream branch into your fork to resolve    any conflicts.</li> </ul> </li> <li>Final Steps After addressing any review comments and completing the version bump, your changes will be merged into     the project.</li> </ol> <p>Additional Tips for a Successful Contribution</p> <ul> <li>Follow Coding Standards Adhere to the coding standards and guidelines provided in the repository documentation to      increase the likelihood of your changes being accepted. </li> <li>Test Thoroughly Before submitting your pull request, thoroughly test your changes to ensure they work as expected      and do not introduce any new issues.</li> </ul> <p>By following these guidelines, you can contribute valuable improvements to osirixgrpc and help enhance its  functionality and user experience.</p>"},{"location":"CONTRIBUTING/#version-control","title":"Version Control","text":"<p>This project uses semantic versioning (<code>major.minor.patch-releasebuild</code>). Any release with <code>major</code> = 0 means that we may  make subtle changes to the technology prior to 1.0.0 (i.e. no promises!).</p> <p>Versioning is controlled by bump2version. Below are the commands available to bump2version within this project, and example increments in each case:</p> <code>bumpversion build</code> 1.0.0-dev0 \u2192 1.0.0-dev1 \u2192 1.0.0-dev2 \u2192 ...  or          1.0.0-rc0 \u2192 1.0.0-rc1 \u2192 1.0.0-rc2 \u2192 ... <code>bumpversion release</code> 1.0.0-dev5 \u2192 1.0.0-rc0 \u2192 1.0.0-beta0 \u2192 1.0.0 <code>bumpversion patch</code> 1.0.0 \u2192 1.0.1-dev0 \u2192 1.0.2-dev0 \u2192 ... <code>bumpversion minor</code> 1.0.2 \u2192 1.1.0-dev0 \u2192 1.2.0-dev0 \u2192 ... <code>bumpversion major</code> 1.2.0 \u2192 2.0.0-dev0 \u2192 3.0.0-dev0 \u2192 ..."},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>All documentation is written in Markdown format and compiled using MkDocs. The organization  of documentation should be kept consistent, and any changes to layout need to be fully discussed and agreed with all developers before being implemented. </p> Name Description assets Location for all figures and other supporting information not in Markdown format. CODE_OF_CONDUCT.md Our Code of Conduct CONTRIBUTING.md Instruction for how to contribute to the project. mkdocs.yaml yaml configuration file for the mkdocs build README.md The homepage for the documentation."},{"location":"CONTRIBUTING/#requirements","title":"Requirements","text":"<p>Building documentation requires both mkdocs and  mkdocs-material to be installed.  These can be installed using the  <code>requirements.txt</code> file within the <code>docs</code> folder: <pre><code>pip install -r docs/requirements.txt\n</code></pre></p>"},{"location":"CONTRIBUTING/#building-documentation","title":"Building Documentation","text":"<p>To build the documentation from source it is sufficient to run the following command, from the <code>docs</code> folder within the project root: <pre><code>mkdocs build\n</code></pre> This will create a new directory, <code>site</code>, which contains all built html documentation for deployment.</p> <p>When developing documentation, however, it can be beneficial to run the MkDocs server (again from the <code>docs</code> folder): <pre><code>mkdocs serve\n</code></pre> By connecting to the established service (linking to <code>http://localhost:8000/</code> in a web-browser), it is then possible to  view changes to documentation in real-time.</p>"},{"location":"CONTRIBUTING/#deploying-documentation","title":"Deploying Documentation","text":"<p>Collaborators should not directly modify the deployed documentation. Instead, this will be performed as part of  continuous integration. Documentation will be deployed from the <code>main</code>branch following a push to the GitHub repository:</p> Branch Site <code>main</code> https://osirixgrpc.github.io/pyosirix_example_project"},{"location":"CONTRIBUTING/#suggesting-changes","title":"Suggesting Changes","text":"<p>If you would like to suggest a change to the documentation please let us know through the project   issue tracker, ensuring you  choose a <code>documentation</code> label for the issue. If you wish to help contribute to the documentation, then please fork the latest copy of the repository, modify it, and submit a pull request to the main branch. </p>"},{"location":"CONTRIBUTING/#bug-reporting","title":"Bug Reporting","text":"<p>If you encounter any bugs with this project then please let us know through the   issue tracker, ensuring you choose a  <code>bug</code> label.  When you raise the issue, please using the relevant template for bugs, which will include the following  information:</p> <ul> <li> What happened? </li> <li> What did you expect to see? </li> <li> What was the error message (if applicable)? </li> <li> What steps could we use to reproduce the bug? </li> <li> Project version. </li> <li> macOS version. </li> <li> Processor (Intel or Mac M1/M2/M3). </li> </ul>"},{"location":"CONTRIBUTING/#feature-requests","title":"Feature Requests","text":"<p>We warmly invite fresh insights and suggestions for enhancing this project. Every piece of feedback is invaluable to us.  While we are committed to incorporating your suggestions to the best of our ability, please remember that this project  thrives on community involvement and operates on a voluntary basis. Consequently, we cannot provide specific timelines  for the introduction of new features.</p> <p>If you wish request new features, please use our   issue tracker ensuring that you use a  <code>feature request</code> label, using the <code>feature_request</code> issue template.  This includes the following information</p> <ul> <li>Short description of the new functionality</li> <li>Why would this improve the functionality of the project?</li> <li>Have you been using any work-around so far?</li> <li>How urgent is the new functionality to you?</li> <li>Would you be willing to help develop/test the new functionality?</li> </ul>"},{"location":"CONTRIBUTING/#issues","title":"Issues","text":"<p>Please use the relevant label for each issue that you submit on the GitHub project.</p> Label Description <code>bug</code> If you encounter a bug then please let us know using the provided template. See Bug Reporting for more information. <code>feature_request</code> What else would you like see in this project? We welcome suggestions. <code>documentation</code> Tell us how we can improve our documentation. This includes everything from fixing spelling mistakes to improving interpretability. <code>generic</code> Any other issue you have with this project."},{"location":"CONTRIBUTING/#contact","title":"Contact","text":"Name Contact Matt Blackledge matthew.blackledge@icr.ac.uk"},{"location":"bumpversion/","title":"Version Control with <code>bump2version</code>","text":""},{"location":"bumpversion/#semantic-versioning","title":"Semantic versioning","text":"<p>It is essential that you signal to your users which version of your code they are using. This helps them to keep track  of which version is compatible with whatever they plan to do in their own solutions, and helps you to communicate how  drastic the changes are that you are making from one version to the next. It also helps you keep up to date with the  changes you are making.</p> <p>This is now done almost universally through semantic versioning. It is a very clear and concise standard, that is easy to interpret and include within your own software. In the below, we will unashamedly \"borrow\" the definitions by the semver organization as it provides the clearest explanation of the core  concepts.</p> Structure of semantic versioning<pre><code>MAJOR.MINOR.PATCH\n</code></pre> <p>Increment:</p> <ul> <li><code>MAJOR</code> version when you make incompatible API changes</li> <li><code>MINOR</code> version when you add functionality in a backward compatible manner</li> <li><code>PATCH</code> version when you make backward compatible bug fixes</li> </ul> <p>There are a few rules that must be adhered to when updating your version:</p> <ul> <li>All elements of the version number must be integers, without leading zeros.</li> <li>During an update, elements can only increase numerically. For instance: <code>1.9.0 -&gt; 1.10.0 -&gt; 1.11.0</code>.</li> <li>Once a versioned package has been released, the contents of that version must not be modified. Any modifications     must be released as a new version.</li> <li><code>PATCH</code>:<ul> <li>Must be incremented if only backward compatible bug fixes are introduced (an internal change that fixes  incorrect behavior). </li> </ul> </li> <li><code>MINOR</code>:<ul> <li>Must be incremented if new, backward compatible functionality is introduced to the public API.</li> <li>Must be incremented if any public API functionality is marked as deprecated. </li> <li>May include patch level changes. </li> <li>Must be reset <code>PATCH</code> to 0 when minor version is incremented. </li> </ul> </li> <li><code>MAJOR</code>: <ul> <li>Must be incremented if any backward incompatible changes are introduced to the public API. </li> <li>May include <code>MINOR</code> and <code>PATCH</code> level changes. </li> <li>Must reset <code>PATCH</code> and <code>MINOR</code> versions to 0 when major version is incremented.</li> </ul> </li> <li><code>MAJOR = 0</code> indicates initial development and anything may change at any time. The public API should not    be considered stable.</li> <li>A pre-release version may be denoted by appending a hyphen (<code>-</code>) and a series of dot separated identifiers     immediately following the patch version (e.g. <code>1.1.3-dev.0</code> is a pre-release for stable version <code>1.1.3</code>). A     pre-release version indicates that the version is unstable. Pre-release identifiers must follow these rules:<ul> <li>Must comprise only ASCII alphanumerics and hyphens (<code>0-9A-Za-z-</code>). </li> <li>Must not be empty. </li> <li>Must_not include leading zeroes.</li> </ul> </li> </ul> Example of semantic version ordering<pre><code>0.0.1-dev.0  (first development phase for version 0.0.1)\n0.0.1-dev.1  (second development phase for version 0.0.1)\n0.0.1-rc.0   (first release candidate for version 0.0.1)\n0.0.1        (unstable release of version 0.0.1)\n0.0.2-dev.0  (first development phase for version 0.0.2)\n0.0.2-rc.0   (first release candidate for version 0.0.2)\n0.0.2        (unstable release of version 0.0.2)\n1.0.0        (stable release of version 1.0.0)\n1.1.0        (stable release of version 1.1.0)\n1.1.1        (stable release of version 1.1.1)\n</code></pre> <p>Note</p> <p>The rules for pre-release are designed to be quite flexible. This is perhaps where you will do most of your development work so it is worth making sure that whatever sytax you use, it makes some sense upfront. Also, it will be helpful to your users to indicate somewhere in your documentation what your coventions are for the pre-release phase to indicate where you are in the development cycle.  For example, in the OsiriXgrpc project this is:</p> <ul> <li><code>0.0.1-dev.0</code>: Unstable release in the development phase of the <code>dev</code> branch, first code push.</li> <li><code>0.0.1-dev.1</code>: Unstable release in the development phase of the <code>dev</code> branch, second code push.</li> <li><code>0.0.1-rc.0</code>: Unstable release in the release-candidate phase of the <code>dev</code> branch, first code push.</li> <li><code>0.0.1</code>: Unstable release in the <code>main</code> branch.</li> <li><code>1.0.0</code>: Stable release in the <code>main</code> branch.</li> </ul> <p>This tells users that if we are in a release-candidate phase, we will not accept any new feature requets until the  next development cycle begins.</p>"},{"location":"bumpversion/#semantic-versioning-with-bump2version","title":"Semantic versioning with <code>bump2version</code>","text":"<p>As your project expands, there will likely be many files that contain a reference to the software version. In this  project, for example, there is a <code>VERSION</code> file to make it very easy to find, but the version is also contained in the <code>mkdocs.yaml</code> file so that all released documentation clearly shows the software version. In fact, there are nine files that contain a reference to the version throughout the project.</p> <p>We would not want to manually update these files every time we push or release code to GitHub. Worse yet, this would  likely lead to errors. This is where <code>bump2version</code> application comes in.  By including a simple <code>.bumpverision.cfg</code> configuration file at the root of your code repository, you can tell  <code>bump2version</code> which files contain a version string and define the version update rules. It can then 'bump' the  version of your entire project with single command.</p>"},{"location":"bumpversion/#installing-bump2version","title":"Installing <code>bump2version</code>","text":"<p>Installing <code>bump2version</code> of your system is easy:</p> <pre><code>pip install bump2version\n</code></pre>"},{"location":"bumpversion/#the-bumpversioncfg-file","title":"The <code>.bumpversion.cfg</code> file","text":"<p>Let's take a look at the <code>.bumpversion.cfg</code> file contained within this project.</p> .bumpversion.cfg<pre><code>[bumpversion]\ncurrent_version = 0.0.1-dev.24\ncommit = True\nmessage = Bump version: {current_version} \u2192 {new_version}\ntag = False\nparse = (?P&lt;major&gt;\\d+)\\.(?P&lt;minor&gt;\\d+)\\.(?P&lt;patch&gt;\\d+)(\\-(?P&lt;release&gt;[a-z]+).(?P&lt;build&gt;\\d+))?\nserialize = \n    {major}.{minor}.{patch}-{release}.{build}\n    {major}.{minor}.{patch}\n\n[bumpversion:part:release]\nfirst_value = dev\noptional_value = void\nvalues = \n    dev\n    rc\n    beta\n    void\n\n[bumpversion:file:VERSION]\n\n[bumpversion:file:pyproject.toml]\nsearch = {current_version}\nreplace = {new_version}\n\n[bumpversion:file:mkdocs.yaml]\nsearch = ver {current_version}\nreplace = ver {new_version}\n\n[bumpversion:file:docs/bumpversion.md]\nsearch = current_version = {current_version}\nreplace = current_version = {new_version}\n\n[bumpversion:file:pyosirix_example/__init__.py]\nsearch = __version__ = \"{current_version}\"\nreplace = __version__ = \"{new_version}\"\n\n[bumpversion:file:.github/ISSUE_TEMPLATE/bug.yaml]\nsearch = placeholder: \"{current_version}\"\nreplace = placeholder: \"{new_version}\"\n\n[bumpversion:file:.github/ISSUE_TEMPLATE/documentation.yaml]\nsearch = placeholder: \"{current_version}\"\nreplace = placeholder: \"{new_version}\"\n\n[bumpversion:file:.github/ISSUE_TEMPLATE/feature_request.yaml]\nsearch = placeholder: \"{current_version}\"\nreplace = placeholder: \"{new_version}\"\n\n[bumpversion:file:.github/ISSUE_TEMPLATE/generic.yaml]\nsearch = placeholder: \"{current_version}\"\nreplace = placeholder: \"{new_version}\"\n</code></pre> <p>Info</p> <p><code>{current_version}</code> and <code>{new_version}</code> are placeholders that will be filled in with the previous and new  version strings.</p>"},{"location":"bumpversion/#bumpversion","title":"<code>[bumpversion]</code>","text":"<p>This section defines the main settings for the version bumping process.</p> <ul> <li><code>current_version = 0.0.1-dev.24</code>: Specifies the current version of the project representing     <code>MAJOR.MINOR.PATCH-RELEASE.BUILD</code>. </li> <li><code>commit = True</code>: Indicates that <code>bump2version</code> will automatically commit to the local git repository after a     successful run.</li> <li><code>message = Bump version: {current_version} \u2192 {new_version}</code>: The message used after a successful git commit.</li> <li><code>tag = False</code>: Tell <code>bump2version</code> not to tag the repository      after a successful bump. </li> <li><code>parse = (?P&lt;major&gt;\\d+)\\.(?P&lt;minor&gt;\\d+)\\.(?P&lt;patch&gt;\\d+)(\\-(?P&lt;release&gt;[a-z]+).(?P&lt;build&gt;\\d+))?</code>: This line defines a      regular expression that bumpversion uses to parse the current version      string into different parts: major, minor, patch, release, and build. It is where you define the rules of your      versioning system. It is highly flexible, though of course here we have aligned with the      semver conventions. This way is pretty standard, and you can leave it as it is if you like.</li> <li><code>serialize</code>: Defines how the version string should be formatted when it is updated. In this case it can either be    <code>MAJOR.MINOR.PATCH</code> or <code>MAJOR.MINOR.PATCH-RELEASE.BUILD</code> and nothing in between (for example <code>1.0.0-rc</code> would not     be possible, and would not make sense as it must have a build number too).</li> </ul> <p>Note</p> <p>The <code>\\d+</code> statement oin the <code>parse</code> regular expression indicates that that component of the version string must be a  positive integer, which bumpversion handles by default for you. The <code>[a-z]+</code> indicates that this component must consist of a sequence of lowercase letters. <code>bump2version</code> does not handle this for you and you need to define the behaviour in the <code>[bumpversion:part:release]</code> of the configuration file.</p>"},{"location":"bumpversion/#bumpversionpartrelease","title":"<code>[bumpversion:part:release]</code>","text":"<p>This section controls how the release part of the version is managed.</p> <ul> <li><code>first_value = dev</code>: Sets the default value of the release part to dev when first incremented.</li> <li><code>optional_value = void</code>: Specifies an optional value (void) that represents a missing or absent release type.</li> <li><code>values</code> Defines the allowed values for the release part of the version in order:<ul> <li><code>dev</code>: Development release - still in the early stage of development (<code>dev</code> branch).</li> <li><code>rc</code>: Release candidate release - internally testing a potentially stable release. No new features (<code>dev</code> branch). </li> <li><code>beta</code>: Beta release - external testing a potentially stable release (<code>main</code> branch).</li> <li><code>void</code>: No release type - this tells <code>bump2version</code> to move to a stable release (remove <code>-RELEASE.BUILD</code>).</li> </ul> </li> </ul>"},{"location":"bumpversion/#bumpversionfilefile_path","title":"<code>[bumpversion:file:&lt;file_path&gt;]</code>","text":"<p>These sections specify the files where the version number should be updated. <code>bump2version</code> will search for the current  version, defined by the <code>{current_version}</code> placeholder, and replace it with the new version, defined by the  <code>{new_version}</code> placeholder.</p> <ul> <li><code>search</code>: Look for instances that match this string in the file.</li> <li><code>replace</code>: Replace the string with this one.</li> </ul>"},{"location":"bumpversion/#running-bump2version","title":"Running <code>bump2version</code>","text":"<p>Running bumpversion is as simple as follows:</p> <pre><code>bumpversion &lt;part&gt;\n</code></pre> <p>where <code>&lt;part&gt;</code> indicates which part of the version you are trying to update. For example, say our starting version is <code>1.1.1-dev.1</code>, below is a history of what happens depending on the bumpversion command you use:</p> Command New version <code>bumpversion build</code> <code>1.1.1-dev.2</code> <code>bumpversion build</code> <code>1.1.1-dev.3</code> <code>bumpversion release</code> <code>1.1.1-rc.0</code> <code>bumpversion build</code> <code>1.1.1-rc.1</code> <code>bumpversion release</code> <code>1.1.1-beta.0</code> <code>bumpversion release</code> <code>1.1.1</code> <code>bumpversion minor</code> <code>1.2.0-dev.0</code> <code>bumpversion major</code> <code>2.0.0-dev.0</code> <code>bumpversion patch</code> <code>2.0.1-dev.0</code> <p>The name of <code>&lt;part&gt;</code> is completely dependent on the name you define for each part in the <code>parse</code> field  of the config file. </p> <p>Warning</p> <p>You must commit all your code changes before running <code>bump2ersion</code> - it will fail and complain otherwise.  </p>"},{"location":"dvc/","title":"Data Version Control (DVC)","text":"<ul> <li>Why is DVC useful in this context: tracks data well (also models)</li> </ul>"},{"location":"dvc/#initiating-dvc","title":"Initiating DVC","text":"<ul> <li><code>dvc init</code></li> </ul>"},{"location":"dvc/#setting-up-gdrive-remote","title":"Setting up gdrive remote","text":"<ul> <li>Advantages to Google Drive</li> <li>Set up a public DVC repository.</li> <li>Adding the remote to the DVC repository (where is this seen?).</li> <li>See here for more information and     options.</li> </ul>"},{"location":"dvc/#steps","title":"Steps","text":"<ol> <li>Go to <code>https://drive.google.com/drive/home</code>.</li> <li>Create a new directory using the <code>+ New</code> button.</li> <li>Go to the drive and select the downward arrow, \u25bc, next to the folder name.</li> <li>Select <code>Share</code> \u2192 <code>Share</code>.</li> <li>In the new window, make sure <code>General access</code> is selected as <code>Anyone with the link</code> and that role is set to <code>Viewer</code>.</li> <li>Make a note of the Folder ID. This is usually available from the URL in the browser address bar.  For example, if    if the URL is <code>https://drive.google.com/drive/folders/1ZduSGJSCuTF4WmhP1bGoXxSRmCQWnJvI</code>, then the ID is    <code>1ZduSGJSCuTF4WmhP1bGoXxSRmCQWnJvI</code>.</li> <li>In your repository, add the Google drive as the default remote using    <code>dvc remote add --default gdrive gdrive://{folder_id}</code>, where <code>{folder_id}</code> is the ID obtained from step 6. The     first <code>gdrive</code> is an arbitrary name that can be changed if needed.</li> <li>Use <code>dvc remote modify gdrive gdrive_acknowledge_abuse true</code></li> </ol> <p>You can see the details of this remote in the <code>.dvc/config</code> file within the repository.</p>"},{"location":"dvc/#adding-tracked-data","title":"Adding tracked data","text":"<ul> <li>File or directory?</li> </ul>"},{"location":"dvc/#steps_1","title":"Steps","text":"<p>From root of repo: 1. <code>dvc add ./path/to/data</code></p>"},{"location":"github/","title":"Continuous Integration and Continuous Deployment (CI/CD) with GitHub","text":""},{"location":"github/#what-is-cicd","title":"What is CI/CD?","text":"<p>Continuous Integration and Continuous Deployment (CI/CD) are essential practices in modern software development,  particularly in methodologies like DevOps and its AI-focused counterpart, MLOps. The primary goal of CI/CD is to  encourage smaller, more frequent code updates, which comes with several benefits:</p> <ul> <li>Improved Code Quality: Frequent updates allow for continuous testing and validation, catching bugs and issues     early in the development cycle.  CI/CD emphasizes a disciplined approach to coding, testing, and deploying that    requires proper infrastructure and practices to be effective.</li> <li>Modular Updates: By keeping changes small and focused, updates are easier to manage, test, and debug, enhancing     overall software design and maintainability. </li> <li>Reduced Risk: Smaller changes reduce the risk of large-scale failures, making the impact of any individual update     less severe. </li> <li>Automated Quality Control: Code quality checks using automated unit testing and linting ensure that    all code is functional and follows proper stylistic conventions at regular intervals and before software release. </li> <li>Faster Delivery: Automated building and deployment streamline the process of delivering software     updates, keeping customers satisfied with quicker access to new features and fixes.</li> </ul> <p>If you want to know more about the theory and practise of CI/CD there is a great  article by Red Hat to get your started on your journey. </p>"},{"location":"github/#cicd-in-github","title":"CI/CD in GitHub","text":"<p>CI/CD automation is managed in GitHub through Actions, with bug reporting, project planning/maintenance,  and \"customer\" support provided through Issues. Actions and issue templates are defined using YAML files,  human-readable data structures often used for configuration of projects and data transfer. It is quite quick to learn and more details can be found in this  nice tutorial.</p>"},{"location":"github/#actions","title":"Actions","text":"<p>GitHub Actions provides support for automating processes within GitHub repositories. It is a highly flexible interface that can allow you to automatically perform operations when some trigger occurs within the repository. This could, for example, be someone pushing code to the repository, creating a release of a specific version of your code, or even somebody creating a new issue. We can only cover the very basics here, but please see the  official documentation provided by GitHub for a more in-depth discussion.</p>"},{"location":"github/#workflow-files","title":"Workflow files","text":"<p>Actions are defined using YAML _workflow files__ contained within the following directory of your project:</p> Location of files defining GitHub actions<pre><code>.github/workflows/\n</code></pre> <p>The structure of these files is relatively straightforward once you get used to them. In this project, for example, there is a <code>unittests.yaml</code> workflow that performs all unit tests everytime code is pushed to the  <code>main</code> or <code>dev</code> branches. The content of this file is shown below - we will break down and explain each of the  components later on.</p> Actions file for automated unit testing (.github/workflows/unittests.yaml)<pre><code>name: Run unit tests  # The name of the action (as displayed on GitHub)\n\n# When do you want the action to occur? Aat present this will only run when pushing to main branch.\non:\n  push:\n    branches:\n      - main\n      - dev\n\n# Tell GH the jobs you want to perform.\n# Side note: Some of these keywords cannot be changed (jobs, runs-on, steps), but some are flexible (e.g. run-tests).\njobs:\n  run-tests:  # We can call this anything we like that makes sense.\n    runs-on: macos-latest  # We will run on this on macOS as that is the final destination.\n\n    # Define each step for the \"run-tests\" job.\n    steps:\n      # Checkout the latest code\n      - name: Checkout\n        uses: actions/checkout@v4  # This s a pre-built \"action\" that someone else has kindly made. It is used frequently!\n\n      # Install python on the shiny new macOS server.\n      - name: Set up Python\n        uses: actions/setup-python@v5  # Another pre-built action.\n        with:\n          python-version: 3\n\n      # Build gRPC libraries\n      - name: Build gRPC Files Workflow\n        uses: ./.github/actions/build_grpc_files  # Calls the composite action\n\n      # Install all our dependencies.\n      - name: Install dependencies\n        run: |  # Using a \"|\" symbol allows you to use a multiline command.\n          python3 -m pip install -r requirements.txt\n          python3 -m pip install setuptools pytest\n\n      # Run the tests, just as you would run it from Terminal.\n      - name: Unit tests\n        run: python -m pytest tests\n</code></pre>"},{"location":"github/#workflow-file-breakdown","title":"Workflow file breakdown","text":"<p>A YAML file is effectively a set of (potentially nested) <code>key: value</code> pairs, much like a dictionary in Python. The three  top-level key-value pairs that must be included in your workflow file are:</p> <ul> <li><code>name</code>: A string that will represent the name of your action. This is how you will identify the action within the     GitHub interface so call it something sensible.</li> <li><code>on</code>: When should the action run? In this instance, we have told it that this happens during a code <code>push</code> event to     either of the <code>main</code> or <code>dev</code> branches. You can list multiple events to trigger the same action. There is a complete    list of events that trigger workflow actions    on the GitHub website.</li> <li><code>jobs</code>: A list of jobs to perform as part of this workflow. In this case there is only a single job, <code>run-tests</code>,     but there can be more than one. By default, jobs runs in parallel, but you can make them dependent on one another     (sequential) using the <code>jobs.&lt;job_id&gt;.needs</code>     option.</li> </ul> <p>Note</p> <p>In YAML, lists are defined by prefixing each element with a hyphen (<code>-</code>), without requiring a specific key for each  element. In the example above, each job in the GitHub Actions workflow is represented as a dictionary, where the key  is the <code>job-id</code>, and the value is a nested dictionary containing the job's details. </p> <p>However, the steps within each job are defined as a list of dictionaries, without explicit keys. This approach  emphasizes that steps are executed sequentially, in the order they are listed, while jobs themselves can run in  parallel or in any order unless dependencies are explicitly defined.</p> <p>Note</p> <p>Just like Python, YAML relies heavily on indentation to define the structure and hierarchy of the data. The level  of indentation indicates which elements are nested within others. In the examples below, the difference in the  indentation of the offices dictionary significantly alters the data structure:</p> <ul> <li>In Definition A, the offices are associated with Alice specifically, as they are indented under her entry in the     people list.</li> <li>In Definition B, the offices are not related to Bob at all. Instead, they are a separate top-level entry outside     the people list.</li> </ul> Definition A<pre><code>people:\n    - name: \"Alice\"\n      offices:\n          - Address: 123 Old Bormpton Road, London, UK\n          - Address: 15 Cotswold Road, Sutton, UK\n</code></pre> Definition B<pre><code>people:\n    - name: \"Bob\"\noffices:\n    - Address: 123 Old Bormpton Road, London, UK\n    - Address: 15 Cotswold Road, Sutton, UK\n</code></pre> <p>There are many options for jobs and their executed steps depending on what you need. We cannot list them all here, but a complete list is provided in the GitHub workflow syntax page. We will go through one used in the example above</p> <ul> <li><code>jobs.&lt;job-id&gt;</code>: The first thing you will notice is that each job is given an ID at the top level. This can be     anything you like, but must only be constructed with alphanumeric, <code>_</code>, or <code>-</code> symbols (cannot start with  latter).     This is used to reference the job within the workflow file and is also visible on the GitHub actions interface.    See here for     more information.</li> <li><code>jobs.&lt;job-id&gt;.runs-on</code>: Tell GitHub which runner to use for the job. This is a virtual machine that can be used    to run the job. If you are using a public repository, most are free, and if you have a private repository, you will     have some allotted free minutes, after which you will be charged (you can set up a spend limit cap, which it \u00a30 by     default). Runners can be Linux, Windows or Mac based, and if you want to pay more, you can get machines with better     specifications (see here    for more information).</li> <li><code>jobs.&lt;job-id&gt;.steps</code>: Each job consists of a number of steps, which will run sequentially. In this example the steps     are<ol> <li>Checkout the latest repository code (from the branch that initiated the action by default).</li> <li>Install Python on the virtual machine runner.</li> <li>Install any package dependencies for the unit tests (defined in the project <code>requirements.txt</code> files).</li> <li>Run the unit tests. </li> </ol> </li> <li><code>jobs.&lt;job-id&gt;.steps.name</code>: A name for the step. This is how you will identify it within the GitHub interface.</li> <li><code>jobs.&lt;job-id&gt;.steps.uses</code>: Some actions can be re-used! This is how you reference one of the GitHub boilerplate    workflows (<code>actions/checkout@v4</code> to checkout your repository and <code>actions/setup-python@v5</code> to install Python),     a third party's workflow, or even one of your own.</li> <li><code>jobs.&lt;job-id&gt;.steps.with</code>: Defines the input parameters to the boilerplate action defined above. In this case, we    tell <code>actions/checkout@v4</code> that we want Python version 3.</li> <li><code>jobs.&lt;job-id&gt;.steps.run</code>: This is where the magic happens! This is where you run commands, just as you would do on    a Terminal on your own machine. If it's a single line command, then just a single line will suffice (as for the <code>Unit     tests</code> step in the example above). However, if you want to run multiple commands in a single step, the <code>|</code> symbol is    used to indicate that a multi-line command prompt will follow (as for the <code>Install dependencies</code> step in the example     above).</li> </ul>"},{"location":"github/#issues","title":"Issues","text":"<p>No matter how many unit tests you design, there will always be a bug in your code that you did not anticipate. One of  the most effective ways to test your code and catch these bugs is to ask your users to let you know if they encounter  something during use (this is an essential part of post-market surveillance when developing software as a medical  device). However, for feedback to be structured and useful, it is important to make sure that your users have somewhere to raise any issues they encounter.</p> <p>GitHub achieves this through Issues, where bugs, new feature requests and software updates can be reported, planned, fixed and released. Advantages to GitHub issues include:</p> <ul> <li>Structured Feedback: Using issue templates you can configure how you get feedback from users    in certain scenarios, such as bugs, feature requests, and documentation fixes. There are no rules for this and these    templates are completely flexible.</li> <li>Transparency and Traceability: GitHub Issues provide a transparent view of all ongoing work within a project.      This traceability helps maintain accountability and provides a historical record of how challenges were addressed,     which is valuable for audits and reviews.</li> <li>Collaboration and Communication: As issues in public repositories are openly available, users are able to see     whether their issues have been encountered by others, and read any feedback, instructions or fixes that were advised     by the community. This is a great way to get others to help with support and documentation. </li> <li>Seamless Integration: GitHub Issues is directly integrated with your code repository, allowing you to link issues     to code commits, pull requests, and branches. This makes it easy to track the status of code changes related to     specific issues.</li> <li>Customizable with Actions: Workflows in GitHub Issues can be automated using Actions using triggers,     such as automatically closing issues when a pull request is merged or sending notifications when an issue is updated.</li> <li>Labels, Milestones, and Assignees: Labels help categorize issues (e.g., bug, enhancement, question), milestones     group issues into specific phases or releases, and assignees clearly define ownership of tasks, helping teams stay     organized.</li> </ul> <p>We will not go into the details of how you use Issues to report bugs and ask for feature requests in other projects, as this ultimately depends on the project. However, we will go through the basics of making an issue template so that you can get feedback from users in a format that is helpful to you and your project in certain scenarios.</p>"},{"location":"github/#issue-templates","title":"Issue templates","text":"<p>Similar to GitHub Actions, issue templates are YAML files stored with a particular directory within your  project:</p> Location of files defining GitHub issue templates<pre><code>./github/ISSUE_TEMPLATE\n</code></pre> <p>Within this project, we have defined four issue templates. These will suffice as a default if you don't want to make  your own changes, and will still be present in your fork.</p> <ul> <li><code>bug.yaml</code> is the template for bug reports.</li> <li><code>documentation.yaml</code> is the template for reporting documentation errors.</li> <li><code>feature_request.yaml</code> is how users ask for new features in the software.</li> <li><code>generic.yaml</code> is for anything not covered in the above three.</li> </ul> <p>When editing one of the template files, it is important to be aware of what each of the yaml keys for these files do:</p> <ul> <li><code>name</code>: A unique name for the issue so that users know to select the right one (required).</li> <li><code>description</code>: A description for the issue that appears in the user interface when choosing a template (required).</li> <li><code>title</code> : A default title that will be pre-populated in the issue submission form (optional).</li> <li><code>labels</code>: A list of all      GitHub labels to be      automatically assigned to the issue (e.g \"bug\") (optional).</li> <li><code>assignees</code>: A list of assignees to be automatically assigned to handle this issue (optional).</li> <li><code>description</code>: Projects that any issues created with this template will automatically be added to. The format of      this key is <code>PROJECT-OWNER/PROJECT-NUMBER</code> (optional).</li> <li><code>body</code>: Where you define the fields of the issue form (required). </li> </ul> <p>Each field of the issue form is then defined following the <code>[body]</code> key using the following key-value pairs:</p> <ul> <li> <p><code>[type]</code>: The type of field (required). Possible values include:</p> <ul> <li><code>checkboxes</code>: The user will select a number of checkboxes.</li> <li><code>dropdown</code>: The user will select one from a number of options.</li> <li><code>input</code>: The user will write a line of text.</li> <li><code>textarea</code>: The user can write multiple lines of text.</li> <li><code>markdown</code>: Provide extra information to the user (not editable).</li> </ul> </li> <li> <p><code>id</code>: A unique identifier (one word) for the element. Only use alphanumeric characters, <code>-</code>, and <code>_</code> (optional).</p> </li> <li><code>attributes</code>: A set of key-value pairs that define the properties of the element (required).</li> <li><code>validations</code>: A set of key-value pairs that set constraints on the element (e.g. is it a required field)     (optional).</li> </ul> <p>Values for the <code>attributes</code> key will be dependent on the type of field. For a full list of these please see the  official documentation.</p> <p>The bug reporting template for this project is reproduced as an example below:</p> Issue template for a bug report (.github/ISSUE_TEMPLATE/bug.yaml)<pre><code># Header information\nname: Bug Report\ndescription: File a bug report\ntitle: \"Bug: \"  # A placeholder for the title.\nlabels: [\"bug\"]\nassignees:\n  - mdblackledge  # PLEASE CHANGE! Who is automatically assigned to this bug (GH account name)\n\n# Body information - one\nbody:\n  # Welcome the issue reporter\n  - type: markdown\n    id: welcome\n    attributes:\n      value: |\n        Thanks for taking the time to fill out this bug report!\n\n  # How can we get in touch with them if needed?\n  - type: input\n    id: contact\n    attributes:\n      label: Contact Details\n      description: How can we get in touch with you if we need more info?\n      placeholder: ex. email@example.com  # The default\n    validations:\n      required: false\n\n  # Ask them what happened, and how we could reproduce the bug during experimentation.\n  - type: textarea\n    id: what-happened\n    attributes:\n      label: What happened?\n      description: |\n        What steps could we use to reproduce the bug?\n      placeholder: |\n        1. The following occurred...\n        2. I expected to see...\n        3. This is a copy of the error text...\n        4. See attached an error file...\n        5. What steps could we use to re-create the issue?\n    validations:\n      required: true\n\n  # What version of the project are they using? Yse current version as placeholder.\n  - type: input\n    id: project-version\n    attributes:\n      label: Project Version\n      description: What version of the project are you running?\n      placeholder: \"placeholder: \"0.0.1-dev.24\"\"\n    validations:\n      required: true\n\n  # What version of macOS are they using?\n  - type: input\n    id: macos-version\n    attributes:\n      label: macOS Version\n      description: What version of MacOS are you running?\n      placeholder: \"13.0.0\"\n    validations:\n      required: true\n\n  # What Mac architecture are they using?\n  - type: dropdown\n    id: architecture\n    attributes:\n      label: Architecture\n      description: What Mac architecture are you using? (output of `arch` from terminal)\n      options:\n        - x86_64 (Intel)\n        - arm64 (Apple Silicon)\n      default: 0\n    validations:\n      required: true\n\n  # Check they are willing to abide by our code of conduct\n  - type: checkboxes\n    id: terms\n    attributes:\n      label: Code of Conduct\n      description: By submitting this issue, you agree to follow our Code of Conduct.\n      options:\n        - label: I agree to follow this project's Code of Conduct\n          required: true\n</code></pre>"},{"location":"grpc/","title":"The client-server model using gRPC","text":"<ul> <li>What are the advantages of this?</li> <li>Why gRPC? Easy to write and easy to set-up a connection.</li> <li>Can be used within a Docker container.</li> </ul>"},{"location":"mkdocs/","title":"MkDocs","text":""},{"location":"mkdocs/#yet-another-markup-language-yaml","title":"Yet Another Markup Language (YAML)","text":""},{"location":"pip/","title":"Python packaging with PIP","text":""},{"location":"pip/#python-package-index-pypi","title":"Python Package Index (PyPI)","text":"<p>Once you've developed your code in a version-controlled repository, sharing the project with other users gives you kudos and (hopefully) makes the software world a better and more efficient place. However, users might not want to download  the entire project repository, which could include unnecessary files like unit tests, configuration files, and other  superfluous data. A more efficient way to share your code is by using the Python Package Index (PyPI). PyPI allows you  to distribute version-controlled packages easily and manages installation and dependencies through <code>pip</code>, ensuring a  smooth experience for both you and your users. Installing your code becomes as simple as <code>pip install my_project</code>.</p> <p>Here are some basic instructions to help you get started. For more detailed guidance, refer to the official pip  documentation and the default backend for pip,  setuptools.</p>"},{"location":"pip/#setting-up-a-pypi-account","title":"Setting up a PyPI account","text":"<p>To upload projects to PyPI, you first need to create a free account on the PyPI website.  Additionally, it's highly recommended to set up an account on TestPyPI, a separate version of  PyPI designed as a staging environment. This allows you to verify that everything works correctly before committing to  the main PyPI server.</p> <p>Once a package is uploaded to PyPI, it\u2019s considered bad practice to remove it, and PyPI will prevent you from  re-uploading the same version. If you encounter issues with a release, there are alternatives, such as \"yanking\" a  specific release. You can read more about these options  here. Using TestPyPI helps ensure that everything is  functioning correctly before you make your final upload to PyPI.</p>"},{"location":"pip/#pypi-tokens","title":"PyPI tokens","text":"<p>PyPI no longer supports upload of projects using standard login credentials, and instead requires you to use  PyPI tokens to verify account access. These tokens are either limited to a specific  project or can provide access to all projects in your account. Once created, PyPI will only show you this token once, so you will need to copy it somewhere safe. To create a token, follow these steps:</p> <ol> <li>Login to your PyPI account settings or     TestPyPI account settings.</li> <li>Look for the section API tokens and click \"Add API token\". </li> <li>Add a name for your token and select the scope to be either project specific or for the entire account.</li> <li>On the next page select the button \"Copy token\".</li> </ol> <p>It is much safer to create a project-specific token. However, if the project does not yet exist on PyPI you will need  to upload the project for the first time using an account-wide token. Perhaps the best way to do this is by storing  one within a <code>.pypirc</code> configuration file on your machine:</p> <ol> <li>In Terminal, use <code>touch ~/.pypirc</code></li> <li>Open the file (<code>open ~/.pypirc</code>) and configure it to look as shown: .pypirc contents example<pre><code>[pypi]\nusername = __token__\npassword = &lt;PyPI token&gt;\n\n[testpypi]\nusername = __token__\npassword = &lt;TestPyPI token&gt;\n</code></pre> where <code>&lt;PyPI token&gt;</code> and <code>&lt;TestPyPI token&gt;</code> are the tokens generated for you by PyPI and TestPyPI respectively.</li> <li>The file stores your token in plain text. Ensure you are the only person who can read the file by typing     <code>chmod 600 ~/.pypirc</code>.</li> </ol> <p>If you feel at any point that these tokens may have been compromised (e.g. computer loss), you can easily delete these tokens on the PyPI/TestPyPI websites and create new ones.</p>"},{"location":"pip/#setting-up-a-pypi-project","title":"Setting up a PyPI project","text":"<p>Distributing your project to PyPI is quite straightforward, but requires some set-up at the beginning of your project  through two key configuration files, <code>pyproject.toml</code> and <code>requirements.txt</code>. </p>"},{"location":"pip/#the-pyprojecttoml-file","title":"The <code>pyproject.toml</code> file","text":"<p>Within your project repository you will need to define a configuration file that tells pip information about your  project, such as its name and version, the developers details, and a brief description. The <code>pyproject.toml</code> file  is the current standard for doing this (superseding <code>setup.py</code>, which you may find in other projects). A Tom's Obvious,  Minimal Language (toml) file is designed to be easy to read by humans, providing all required configuration options in  a single file. The key sections to this file are:</p>"},{"location":"pip/#build-system","title":"<code>[build-system]</code>","text":"<p>This tells pip which backend to use. Here we use the default setuptools, but others  exist, including hatch. You can leave this as it is. [build-system] example<pre><code>[build-system]\nrequires = [\"setuptools\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n</code></pre></p>"},{"location":"pip/#project","title":"<code>[project]</code>","text":"<p>This defines project specific characteristics, which must be adapted for your project. - <code>name</code>: The name of the project as it will be defined on PyPI (<code>pip install xyz</code>, where <code>name = \"xyz\"</code>). - <code>version</code>: The package version. Should match that of your repository - see bumpversion. - <code>description</code>: A short description of your package. - <code>authors</code>: A list, <code>[]</code>, of tables, <code>{}</code> defined in toml format describing the package authors. - <code>maintainers</code>: Similar to above, but who is looking after the project moving forward. - <code>readme</code>: Defines the information people will see when looking at your project on PyPI. - <code>license</code>: The license file for your project. Let users know what they can do with your code - there are     templates to choose from. - <code>keywords</code>: List some keywords for PyPI. Perhaps this helps with a search, but I'm not entirely sure. - <code>classifiers</code>: A list \"Trove classifiers\" for each release, describing who it's for, what systems it can run on, and     how mature it is (see here for a list). [project] example<pre><code>[project]\nname = \"pyosirix_example_project\"\nversion = \"0.0.1-dev.24\"\ndescription = \"An example of a Python project that can be used to install into OsiriX\"\nauthors = [\n    { name = \"Matthew D Blackledge\", email = \"matthew.blackledge@icr.ac.uk\" }\n]\nmaintainers = [\n  {name = \"Matthew D Blackledge\", email = \"mattyblackledge@gmail.com\"}\n]\nreadme = \"docs/README.md\"\nlicense = {name = \"MIT\", file = \"LICENSE.txt\", url = \"https://opensource.org/license/mit\"}\nkeywords = [\n    \"Dicom\",\n    \"Medical Imaging\",\n    \"Image Processing\",\n]\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"Development Status :: 3 - Alpha\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Natural Language :: English\",\n    \"Operating System :: MacOS :: MacOS X\",\n]\n</code></pre></p>"},{"location":"pip/#tooltool_name","title":"<code>[tool.tool_name]</code>","text":"<p>This section is used for tool-specific configurations (setuptools in this instance). There are many options available  depending on which back end you use so make sure to check out the documentation for a full breakdown. The ones below are a bare minimum. - <code>packages</code>: Tells pip the name of the packages that will be installed (in python use <code>import xyz</code> if    <code>packages = [\"xyz\"]</code>). Must reflect the name of the directory where the source code is located! - <code>dependencies</code>: Tells pip what the essential libraries are for compatability (see     requirements). [tool.tool_name] example<pre><code>[tool.setuptools]\npackages = [\"pyosirix_example\",\n            \"pyosirix_example.client\",\n            \"pyosirix_example.server\",\n            \"pyosirix_example.utilities\"]\ninclude-package-data = true\n\n[tool.setuptools.dynamic]\ndependencies = {file = [\"requirements.txt\"]}\n\n# Include all necessary server data files in the package\n[tool.setuptools.package-data]\npyosirix_example = [\"server/data/*.dvc\"]\n</code></pre></p>"},{"location":"pip/#the-requirementstxt-file","title":"The <code>requirements.txt</code> file","text":"<p>This file lists all the dependencies of this project. Here we use the bare minimum and just define the names of  important packages.  However, it is also standard to define which version of the library you need. I have found that the more stringent the library version, and the more libraries needed, the higher the chance you might run into conflict on some else's machine.</p> <p>Below are the possible options for defining ranges of library versions: Example library definitions<pre><code>requests&gt;=2.25.1,&lt;2.26.0    # Must be within a range of versions\nnumpy==1.19.3               # Must be a specific version\nscipy&lt;=1.6.0                # Must be at least as old as a particular version\npandas&gt;=1.1.0               # Must be at least as new as a particular version\nflask!=1.1.1                # Must not be a specific version\n</code></pre></p> <p>It is possible to automatically generate a requirements file using the <code>pip freeze &gt; requirements.txt</code> command, but this dumps every library in your current environment, and it's specific version to file. This is far too restrictive  for another user who might disagree with your choice of library version for something completely unrelated.</p> <p>A better option is (pipreqs)[https://github.com/bndr/pipreqs], which searches through your project and creates a  <code>requirements.txt</code> file based on your <code>import</code> statements. It is easy to install using <pre><code>pip install pipreqs\n</code></pre> A suggested use would then be <pre><code>pipreqs . --force --mode gt\n</code></pre> which would force an overwrite of your current requirements.txt file, ensuring that each library version is at least  as new as the one on your system. Note that once you have created your <code>requirements.txt</code> file, it is worthwhile  giving it a check and adding anything pipreqs may have missed!</p> requirements.txt for this project<pre><code>numpy\nPillow\ndvc\npyosirix\n</code></pre>"},{"location":"pip/#project-distribution-manual-approach","title":"Project distribution (manual approach)","text":"<p>Once you are ready to distribute your project, this is done using two tools: <code>build</code> and <code>twine</code>: </p> <ol> <li> <p>Ensure that both libraries are up-to-date <pre><code>pip install --upgrade build twine\n</code></pre></p> </li> <li> <p>Ensure that dependent libraries within <code>requirements.txt</code> are installed: <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Move to the root directory of your repository, and build a distribution. <pre><code>cd /path/of/repo\npython -m build\n</code></pre> When successful, this should create a <code>dist</code> directory within your project (ensure that this is included in your <code>.gitignotre</code> file).</p> </li> <li> <p>Upload to TestPyPI: <pre><code>twine upload --repository testpypi dist/*\n</code></pre></p> </li> <li> <p>Check all is working well by creating a  new conda environment and trying to install your package by using (in the case of this project): <pre><code>pip install -i https://test.pypi.org/simple/ pyosirix_example_project\n</code></pre></p> </li> <li> <p>Once you are happy with this then you can upload to the main server: <pre><code>twine upload --repository pypi dist/*\n</code></pre></p> </li> </ol>"},{"location":"pip/#distribution-with-github-automatic-approach","title":"Distribution with GitHub (automatic approach)","text":"<p>Use of manual steps such as those above can lead to errors and does not fit in well with the concept of automated \"continuous integration/continuous development\" (CI/CD). It can be much more effective to let GitHub take care of the  upload to PyPI for you through Actions. One of the issues with this is that it does not allow you to check  how your library works on TestPyPI before the final upload to PyPI. There are multiple solutions to this, but in this  project we do it by having two branches: \"main\" and \"dev\". GitHub Actions is configured to send to upload to TestPyPI  when code is pushed to the \"dev\" branch, and to PyPI when pushed to the \"main\" branch.</p> <p>GitHub allows you store sensitive information, such as PyPI/TestPyPI tokens as a project-specific secret, which may then be used by Actions to automatically provide login credentials. These are not observable to collaborators on a  project, but with certain access may be used by them when performing actions from their account. It is a good idea to ensure, however, that these tokens are only project specific in scope. However, If you have not yet uploaded your  project to PyPI or TestPyPI, you will not yet be able to generate a project-specific token. So it is advised that the first upload be performed manually, using your account token.</p> <p>To add a token to GitHub secrets, perform the following:</p> <ol> <li>Generate a token as above, ensuring its scope is only for the project.</li> <li>Go to your project on GitHub, and find your project \"Settings\" tab.</li> <li>On the list of options on the left, select \"Secrets and variables\" then click on \"Actions\".</li> <li>Click on \"New repository secret\".</li> <li>Give your secret a name, <code>PYPI_TOKEN</code> for example, but it must match the name used in the     workflow yaml file for the Action (see example below).</li> <li>Paste the token in \"Secret\" box.</li> <li>Click \"Add secret\".</li> </ol> GH Actions specification for PyPI upoload<pre><code>name: Distribute project code to PyPI (TestPyPI if from dev)\n\non:\n  push:\n    branches:\n      - main\n      - dev\n\njobs:\n  publish-pypi:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: 3\n\n      - name: Build gRPC Files Workflow\n        uses: ./.github/actions/build_grpc_files  # Calls the composite action\n\n      - name: Install dependencies\n        run: |\n          python3 -m pip install --upgrade build twine\n          python3 -m pip install -r requirements.txt\n\n      - name: Add repository details to __init__.py\n        run: |\n          sed -i \"s|REPO_PLACEHOLDER|${GITHUB_REPOSITORY}|\" pyosirix_example/__init__.py\n          sed -i \"s|HASH_PLACEHOLDER|$(git rev-parse HEAD)|\" pyosirix_example/__init__.py\n        shell: bash\n\n      - if: github.ref == 'refs/heads/dev'\n        name: Build and publish project (dev)\n        run: |\n          python3 -m build\n          python3 -m twine upload --repository testpypi dist/*\n        env:\n          TWINE_USERNAME: __token__\n          TWINE_PASSWORD: ${{ secrets.PYPI_TEST_TOKEN }}\n\n      - if: github.ref == 'refs/heads/main'\n        name: Build and publish project (main)\n        run: |\n          python3 -m build\n          python3 -m twine upload --repository pypi dist/*\n        env:\n          TWINE_USERNAME: __token__\n          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}\n</code></pre>"},{"location":"plugin_instructions/","title":"Plugin Instructions","text":""},{"location":"pyosirix/","title":"pyOsiriX","text":""},{"location":"pytest/","title":"Unit testing with pyTest","text":"<p>Unit tests are a crucial component of any well-maintained code repository. Not only do they ensure that your code  functions correctly, but they also help you verify that your code continues to work as expected when you update or  modify specific parts. This is especially important in the context of Continuous Integration/Continuous Delivery  (CI/CD), where code is frequently updated \u2014 sometimes by other developers. Unit tests help ensure that these changes do  not disrupt the core functionality of your work, enabling safe integration of new changes.</p> <p>There are several additional benefits to writing unit tests:</p> <ul> <li>Promotes Modular Code Development: Writing unit tests alongside your code encourages you to design your code in     a modular fashion, breaking it down into smaller, more manageable functions or methods that each handle a single     responsibility. This practice not only improves the quality of your code but also makes you a better developer over    time. </li> <li>Provides Usage Examples: Unit tests serve as practical examples of how your code is intended to be used. This     can be beneficial not only for other developers who may work on the codebase but also for you when revisiting the     project after some time. </li> <li>Highlights Performance Bottlenecks: By regularly running unit tests, you can identify which parts of your code     are most resource-intensive, allowing you to focus on optimizing these areas in future development efforts. </li> <li>Meets Industry Standards: Many international coding standards, commercial organizations, and auditing bodies     view unit tests as a foundational element of safe and reliable software development. This is particularly critical     in fields like medical research, where code quality directly impacts safety and compliance.</li> <li>Catching Bugs Early: Unit tests allow you to identify bugs and issues early in the development process, often     before the code is integrated with other parts of the system. This early detection reduces the cost and effort     required to fix issues compared to finding them later in the development cycle.</li> <li>Encourages Code Reuse: Writing unit tests often encourages the development of smaller, more modular components,    which are easier to reuse across different parts of the codebase or in other projects.</li> <li>Promotes Code Ownership: In teams, unit tests help promote a sense of shared ownership of the code. When tests    are in place, all team members can confidently make changes, knowing that the tests will help safeguard the     integrity of the codebase.</li> </ul>"},{"location":"pytest/#what-is-a-unit-test","title":"What is a unit test?","text":"<p>A unit test is a piece of code (written by you) that tests that a particular function is working as you would expect it  to. Typically, as input it will take some data, either pre-defined, simulated, or acquired, and for which you know what  the output should be when given to your particular function. </p>"},{"location":"pytest/#example-of-a-testable-unit-of-code","title":"Example of a testable unit of code","text":"<p>As an example, we have been asked to write a software function that accepts as input a weight in kilograms (kg) and  converts it into pounds (lb). Let's assume that the conversion rate is (to 5 decimal places): $$ 1 \\text{kg} = 2.20462 \\text{lb} $$ Our code might be something simple like <pre><code>def convert_kg_to_lb(weight_kg: float) -&gt; float:\n    \"\"\" Converts weight in kilograms to pounds (to 5.d.p)\n\n    Assumes conversion of 1 kg = 2.20462 lb\n\n    Args:\n        weight_kg (float): The weight in kg.\n\n    Returns:\n        float: The weight in lb    \n    \"\"\"\n    return round(weight_kg * 2.20462, 5)\n</code></pre></p>"},{"location":"pytest/#first-unit-test","title":"First unit test","text":"<p>In this case our unit test could be (typically written in a different python file): <pre><code>from module import convert_kg_to_lb  # Replace 'module' with actual name of the module where function is located\n\ndef test_convert_kg_to_lb():\n    assert convert_kg_to_lb(1) == 2.20462, f\"bad conversion for 1\"  # Test a simple case\n    assert convert_kg_to_lb(0) == 0, f\"bad conversion for 0\"  # Test zero\n    assert convert_kg_to_lb(-1) == -2.20462, f\"bad conversion for -1\"  # Test negative weight\n    assert convert_kg_to_lb(100) == 220.462, f\"bad conversion for 100\"  # Test a larger number\n    assert convert_kg_to_lb(2.5) == 5.51155, f\"bad conversion for 2.5\"  # Test with a fractional weight\n    assert convert_kg_to_lb(0.001) == 0.00220462, f\"bad conversion for 0.001\"  # Test with a very small weight\n</code></pre> There are no rules as to what ranges of data you should try - this depends on the problem at hand and is up to you.</p> <p></p> <p>Note</p> <p>It is essential that the name of the test makes sense. It must start with <code>test</code> in order for pyTest to  recognize it as one and run it. What follows should tell the reader which function you are going to test. There  is no sense in using names like <code>test1</code> or <code>test_a</code>, because it will be difficult to know which method this is  suposed to be testing. It is good practise to use <code>test_name_of_method</code> to make it clear. It also help to add a  docstring for the unit test method that helps the reader know what the test is suposed to achieve, but not essenital if the code is well written.</p> <p>One thing you will notice straight away is the use of the keyword <code>assert</code>. This is just handy shorthand for the  following, but much easier to read: <pre><code>if convert_kg_to_lb(1) != 2.20426:\n    raise AssertionError(\"bad conversion for 1\")\n</code></pre></p> <p>The important part is that when this error is encountered by a test runner (PyTest in our case), this does not stop  the rest of the tests from executing. It will simply record the failure and report it to you as part of the summary  statistics on the tests at the end of the test run (of course you are aiming for no failures!).</p> <p>Tip</p> <p>I have found that ChatGPT is quite good at developing a unit test for you - at least it can be a good place to  start. It is important that you go through all the tests and ensure they are doing what you expect and that they  cover the ranges of inputs/outputs you are expecting to see in your method, and handle exceptions gracefully.</p>"},{"location":"pytest/#testing-for-errors","title":"Testing for errors","text":"<p>In the example provided above, you will notice that we have explicitly allowed (and tested for) negative weights. In reality, we would like to check that our function handles infeasible values gracefully. Here is a revised version of  our code:</p> <pre><code>def convert_kg_to_lb(weight_kg: float) -&gt; float:\n    \"\"\" Converts weight in kilograms to pounds\n\n    Args:\n        weight_kg (float): The weight in kg.\n\n    Returns:\n        float: The weight in lb    \n\n    Raises:\n        ValueError: When a negative weight is provided as input.\n    \"\"\"\n    if weight_kg &lt; 0:\n        raise ValueError(\"weight_kg must be positive!\")\n    return weight_kg * 2.20462\n</code></pre> <p>The unit test should now explicitly test for this exception also: <pre><code>import pytest\nfrom module import convert_kg_to_lb  # Replace 'your_module' with actual name of the module where function is located\n\ndef test_convert_kg_to_lb():\n    assert convert_kg_to_lb(1) == pytest.approx(2.20462, abs=1e-6), f\"bad conversion for 1\"\n    assert convert_kg_to_lb(0) == pytest.approx(0, abs=1e-6), f\"bad conversion for 0\" \n    assert convert_kg_to_lb(100) == pytest.approx(220.462, abs=1e-6), f\"bad conversion for 100\" \n    assert convert_kg_to_lb(2.5) == pytest.approx(5.51155, abs=1e-6), f\"bad conversion for 2.5\" \n    assert convert_kg_to_lb(0.001) == pytest.approx(0.00220462, abs=1e-6), f\"bad conversion for 0.001\"\n\ndef test_convert_kg_to_lb_negative_value():\n    # Test that a negative weight raises a ValueError with the correct message returned.\n    with pytest.raises(ValueError, match=\"weight_kg must be positive!\"):\n        convert_kg_to_lb(-1)\n</code></pre> Not only does this check that the right kind of error is raise, but that the error message is correct (via the  <code>match</code> keyword).  </p>"},{"location":"pytest/#testing-approximations","title":"Testing approximations","text":"<p>Notice that in the above we have also introduces the <code>pytest.approx</code> method. This is useful when comparing  floating-point numbers which may not be identical due to machine precision. You just need to specify how close they  should be (via the <code>abs</code> keyword). Here we have settled for <code>abs=1e-6</code> as our method returns values to 5.d.p. This is  useful because if we were to update the implementation of <code>convert_kg_to_lb</code> method to use a more precise conversion of <code>1 kg = 2.2046226218488 lb</code>, these tests would still pass, confirming the change did not break anything. </p> <p>Note</p> <p>If we extended the accuracy of the returned value from <code>convert_kg_to_lb</code>, say to 8 decimal places, this would  require us to redefine the precision of our unit tests (<code>abs=1e-9</code> for example). Also, we should inform our users  that the change is going to occur in advance so that they can make their code ready for the update, or ensure they  don't use the new version (see version control). You start to see why even making small  changes to well used codebases can result in all kinds of issues for developers down the line. </p> <p>Tip</p> <p><code>pytest.approx</code> deals well with Numpy arrays!</p>"},{"location":"pytest/#using-pytest","title":"Using PyTest","text":"<p>PyTest is an example of a test runner, which orchestrates the execution of tests and  provides the outcome to the user. There are others available, including the in-built  <code>unittest</code> and <code>nose</code> to name a few. However, PyTest is now one of the more widely used as it provides one of the most readable formats for unit tests, with each test being an isolated function, rather than a method of a dedicated class.</p>"},{"location":"pytest/#organizing-your-test-directory","title":"Organizing your test directory","text":"<p>So that PyTest knows where to look for unit tests, you need to ensure that the directory structure and filenames are appropriate. To make your code readable it is advised you put them all in a directory called <code>tests</code> in the root of the  repository. The structure of this directory is up to you, but it should make sense to the reader (e.g. one subdirectory  per Python package). </p> <p>For each test file, it is essential that the name of file starts with <code>test</code> (as for the  method names), so that PyTest knows to run it. This example project has the test files and  folders structured as follows:</p> <pre><code>pyosirix_example_project/ \n\u251c\u2500\u2500 tests/                \n\u2502   \u2514\u2500\u2500 utilities/                    # Matches package name being tested (1) \n\u2502       \u251c\u2500\u2500 conftest.py\n\u2502       \u251c\u2500\u2500 test_text_2_image.py      # Module name with \"test_\" prefix (2)\n\u2502       \u2514\u2500\u2500 test_unit_conversions.py  # Module name with \"test_\" prefix\n</code></pre> <ol> <li>A Python package is a directory of python files with a <code>__init__.py</code> file contained.</li> <li>A Python module is a python file containing methods, classes and so on.</li> </ol> <p>Note</p> <p>This project also contains a <code>pyosirix_operations</code> subpackage. Unfortunaately this does not lend itself well to unit testing as it requires OsiriX or Horos to be active when being used and is thus not automatable (at present). This is where the conecpt of user testing becomes more appropriate, but we will not yet go into that here until the processes are more established within the pyOsiriX project itself.</p>"},{"location":"pytest/#sharing-data-using-pytest-fixtures","title":"Sharing data using PyTest fixtures","text":"<p>A pytest fixture is a piece of code that can be reused across multiple test methods, in order to reduce code redundancy. This could, for example, be loading in test data or defining a shared instance of some created Python class. There are four scopes for each fixture:</p> <ol> <li><code>function</code>: set up and tear down the resource for each test function.</li> <li><code>class</code>: set up and tear down the resource for each test class.</li> <li><code>module</code>: set up and tear down the resource for each test file.</li> <li><code>session</code>: set up and tear down the resource for each test session (e.g. all test files being run).</li> </ol> <p>If the fixture is defined within a test module, it is available only to those methods in the module. If it is defined in a <code>conftest.py</code> file within the test package, then it is available to all modules within that package. The following  examples demonstrate fixtures for testing the  numpy.sum and  numpy.cumsum methods:</p> tests/conftest.py<pre><code>\"\"\" An example configuration file to demonstrate package-wide fixture sharing. \"\"\"\n\nimport pytest\n\n\n@pytest.fixture(scope='function')\ndef shared_data():\n    \"\"\" Example fixture, yielding test data shared across all test files in this directory.\n    \"\"\"\n    yield [1, 2, 3, 4, 5]\n</code></pre> tests/numpy/test_numpy_sum.py<pre><code>\"\"\" An example test file to demonstrate local fixture sharing. \"\"\"\n\nimport pytest\nimport numpy as np\n\n\n@pytest.fixture(scope=\"function\")\ndef local_data():\n    \"\"\" This fixture can only be used in this module. \"\"\"\n    yield [-2, -1, 0, 1, 2]\n\n\ndef test_numpy_sum_shared(shared_data):\n    assert np.sum(shared_data) == pytest.approx(15, abs=1e-3)\n\n\ndef test_numpy_cumsum_shared(shared_data):\n    assert np.cumsum(shared_data) == pytest.approx([1, 3, 6, 10, 15], abs=1e-3)\n\n\ndef test_numpy_sum_local(local_data):\n    assert np.sum(local_data) == pytest.approx(0, abs=1e-3)\n\n\ndef test_numpy_cumsum_local(local_data):\n    assert np.cumsum(local_data) == pytest.approx([-2, -3, -3, -2, 0], abs=1e-3)\n</code></pre>"},{"location":"pytest/#running-pytest","title":"Running PyTest.","text":"<p>Running PyTest for a single set of unit tests is as simple as running the following from your Terminal from the base  directory of the repository: <pre><code>python -m pytest tests/utilities/test_unit_conversions.py\n</code></pre></p> <p>The output should look something like: <pre><code>=============================== test session starts ================================\nplatform darwin -- Python 3.9.13, pytest-6.2.4, py-1.11.0, pluggy-0.13.1\nrootdir: /Users/adminmblackledge/Documents/Projects/pyosirix_example_project\nplugins: anyio-3.6.1, hydra-core-1.3.2, dvc-3.5.1\ncollected 2 items\n\ntests/test_unit_conversions.py ..                                            [100%]\n\n================================ 2 passed in 0.22s =================================\n</code></pre> A nice concise indication that everything is working as expected.</p> <p>Alternatively, if you want to run the entire unit test suite in the directory, you can run: <pre><code>python -m pytest tests\n</code></pre></p> <p>If you use PyCharm to develop your code, it should also provide a little green play symbol  (\u25b6) next to the test function definition to run it in isolation (a great way to  test your unit test!). You can also run the file to run all tests within the file - there are many options.</p> <p>Note</p> <p>As unit tests are so widely used the chances are that most IDEs (1) will have some functionality for running unit  tests graphically.</p> <ol> <li>IDE = Integrated Development Environment</li> </ol>"},{"location":"pytest/#automating-unit-tests-with-github-actions","title":"Automating unit tests with GitHub Actions","text":"<p>It is highly valuable to run unit tests on your code everytime you push changes to a repository like GitHub. This  demonstrates to both yourself and any users that a particular code version has passed all checks and is still working as anticipated. In GitHub this can be done using actions, which are configured to run following certain GitHub events (push, release and so on). In this project, unit tests are configured to run as defined in the  <code>unittests.yaml</code> file (reproduced below). It will run every time code is pushed to the <code>main</code> or <code>dev</code> branches. You would not need to change this if you follow the steps above for setting up your  test directory structure.</p> .github/workflows/unittests.yaml<pre><code>name: Run unit tests  # The name of the action (as displayed on GitHub)\n\n# When do you want the action to occur? Aat present this will only run when pushing to main branch.\non:\n  push:\n    branches:\n      - main\n      - dev\n\n# Tell GH the jobs you want to perform.\n# Side note: Some of these keywords cannot be changed (jobs, runs-on, steps), but some are flexible (e.g. run-tests).\njobs:\n  run-tests:  # We can call this anything we like that makes sense.\n    runs-on: macos-latest  # We will run on this on macOS as that is the final destination.\n\n    # Define each step for the \"run-tests\" job.\n    steps:\n      # Checkout the latest code\n      - name: Checkout\n        uses: actions/checkout@v4  # This s a pre-built \"action\" that someone else has kindly made. It is used frequently!\n\n      # Install python on the shiny new macOS server.\n      - name: Set up Python\n        uses: actions/setup-python@v5  # Another pre-built action.\n        with:\n          python-version: 3\n\n      # Build gRPC libraries\n      - name: Build gRPC Files Workflow\n        uses: ./.github/actions/build_grpc_files  # Calls the composite action\n\n      # Install all our dependencies.\n      - name: Install dependencies\n        run: |  # Using a \"|\" symbol allows you to use a multiline command.\n          python3 -m pip install -r requirements.txt\n          python3 -m pip install setuptools pytest\n\n      # Run the tests, just as you would run it from Terminal.\n      - name: Unit tests\n        run: python -m pytest tests\n</code></pre>"},{"location":"assets/","title":"Assets","text":"<p>This is one way of storing assets for your documentation.  Files that are not specific to the documentation, such as  images, audio files, presentation and so on.  </p> <p>Note that these would likely be under version control, so it is worthwhile keeping their size and number to a  minimum or you may end up bloating your repository for files that have little overall utility in your project.</p>"}]}